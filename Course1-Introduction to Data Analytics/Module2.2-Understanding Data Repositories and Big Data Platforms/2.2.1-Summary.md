## Summary


A **Data Repository** refers to data that has been collected, organized, and isolated for reporting, analytics, and archival purposes.

The different types of Data Repositories include:

- **Databases**: Can be relational or non-relational, organized for storing and retrieving data using specific tools and principles.
- **Data Warehouses**: Consolidate incoming data into a comprehensive storehouse.
- **Data Marts**: Sub-sections of a data warehouse focused on a particular business function or use case.
- **Data Lakes**: Serve as repositories for structured, semi-structured, and unstructured data in their native format.
- **Big Data Stores**: Provide distributed infrastructure for storing, scaling, and processing very large data sets.

The **ETL Process** (Extract, Transform, Load) is an automated process that converts raw data into analysis-ready data by:

- **Extracting** data from source locations.
- **Transforming** data by cleaning, enriching, standardizing, and validating it.
- **Loading** the processed data into a destination system or repository.

A **Data Pipeline**, often used interchangeably with ETL, refers to the journey of moving data from the source to a destination, typically a data lake or application.

**Big Data** refers to the vast volume, velocity, and variety of data produced daily by people, tools, and machines. These challenges are addressed by specialized tools and platforms such as **Apache Hadoop**, **Apache Hive**, and **Apache Spark**.
